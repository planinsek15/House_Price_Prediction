Tukaj se uporabi "scikit-learn" za napoved cen hiÅ¡. 

Tehnike, ki se bodo uporabile so: Linearna regresija, podatkovna obdelava(pandas, matplotlib), metrike uspeÅ¡nosti. 

Iz tukaj naj bi se pobiralo podatke "https://www.kaggle.com/datasets/altavish/boston-housing-dataset". Kasneje lahko narediÅ¡ tudi za nepremiÄnine.net. 

- KAJ JE "scikit-learn"?
Najbolj uporabna knjiÅ¾nica za uÄenje strojev (ML - machine learning) v Pythonu. PraktiÄno dobiÅ¡ neke metrike in pa grafe s katerimi ponazoriÅ¡ neke podatke. 

Spletna stran te knjiÅ¾nice:
![[Pasted image 20250518144038.png]]

Potek izdealve: 
1. **Priprava okolja** - lahko uporabiÅ¡ Google Colab, kjer je bolj pregledna koda. UporabiÅ¡ Python jezik. inÅ¡talacija knjiÅ¾nic (`pandas`, `numpy`, `matplotlib`, `scikit-learn`)
2. **Pridobitev podatkov** - podatki se nahajajo v CSV datoteki ter iz nje bo potrebno prebrati podatke.  
3. **Cilj:** Razumeti strukturo podatkov.

	Koraki:
	
	- NaloÅ¾i podatke z `pandas.read_csv()`
	    
	- Uporabi `.head()`, `.info()`, `.describe()` za osnovne informacije
	    
	- NariÅ¡i grafe:
	    
	    - Histogrami (`df.hist()`)
	    
	    - Korelacijska matrika (`df.corr()`)
	    
	    - Scatter plot med npr. â€œpovrÅ¡inaâ€ in â€œcenaâ€

4. **Pripravi podatke - Koraki:**

	- Ugotovi manjkajoÄe vrednosti in jih odpravi (`df.isnull().sum()`)
	
	- Razdeli podatke na **X (vhodni podatki)** in **y (izhod â€“ cena)**
	
	- Standardiziraj vrednosti (npr. `StandardScaler()` iz `sklearn.preprocessing`)
	
	- Razdeli na **trening in testni set** (`train_test_split`)

5. Zgradi in treniraj model - Uporabi linearno regresijo.
6. Evalvacija modela - Izmeri natanÄnost.
7. Shrani model (bonus)
8. NapiÅ¡i poroÄilo (zase)

*********************************************************
**PRIPRAVA OKOLJA** 
""""""""""""""""""""""
InÅ¡talirali smo jupyter notebook (pip install jupyter notebook) ter ostale knjiÅ¾nice (pip install pandas numpy matplotlib scikit-learn).

Delal bom v VS Code ker sem bolje navajen in tudi bolj sem seznanjen kot z Google Colab, Äeprav je tam mogoÄe bolj pregledno. 

*********************************************************
**PRIDOBITEV PODATKOV**
""""""""""""""""""""""""""""

RoÄno sem pridobil CSV datoteko in jo shranil pod ta projekt (C:\Users\david\Desktop\MYGoals\MaterOfAI\Master of AI\Zacetniski_nivo\Napoved_cene_hise).  


*********************************************************
**RaziÅ¡Äi podatke (Exploratory Data Analysis â€“ EDA)**
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Za zaÄetek sem pognal to kodo: 
```
import pandas as pd

#Preberemo csv file

result_of_csv_read = pd.read_csv('HousingData.csv')

print(result_of_csv_read)
```

S pomoÄjo knjiÅ¾nice pandas sem prebral podatke iz CSV datoteke in pogledal kaj dobim kot rezultat. 

Rezultat je prikazan spodaj na sliki. Vidimo, da so podatki lepo urejeni po vsako vrstico posebej in tudi prikazani imamo koliko je vrstic in pa stolpcev. 

![[Pasted image 20250518165546.png]]

Sedaj bom testiral funkcije `.head()`, `.info()`, `.describe()`:

- **head()** - to je funkcija, ki nam prikaÅ¾e doloÄeno Å¡tevilo vrstic, Äe vstavimo Å¡tevilko v oklepaje. ÄŒe Å¡tevilke ne navedemo nam vrne prvih pet vrstic. Vedno pa prebere vrstice od zaÄetka. 

Se pravi mi smo dobili lepo izpisane vrstice in s pomoÄjo head() funkcije lahko izpiÅ¡emo doloÄeno Å¡tevilo vrstic, da ne rabimo vedno prikazati vseh. Sej ti tudi sam program, ko ga poÅ¾eneÅ¡ ne izpiÅ¡e vseh 500 vrstic, ampak ti samo par zaÄetnih in par konÄnih. 

Prvi rezultat je defoltni, drugi rezultat je, ko sem vstavil Å¡tevilko 10.  
![[Pasted image 20250518174627.png]]

```
import pandas as pd 

result_of_csv_read = pd.read_csv('HousingData.csv')

print(result_of_csv_read.head())
print(result_of_csv_read.head(10))
```

- **info()** - kot vidimo na spodnji sliki, nam ta funkcija vrne povzetek seznama vseh stolpcev z njihovimi podatkovnimi tipi in Å¡tevilom nenull vrednosti v vsakem stolpcu. 

![[Pasted image 20250523071724.png]]

```
import pandas as pd 

result_of_csv_read = pd.read_csv('HousingData.csv')

print(result_of_csv_read.info())`
```

Imamo tudi neke dodatne parametre, ki jih lahko dodamo: 

ÄŒe nastavimo verbose na False nam ne izpiÅ¡e tabele ampak poda krajÅ¡i opis vsega kar imamo. To nam pride prav v primeru Äe imamo na tisoÄe vrstic. 

```
print(result_of_csv_read.info(verbose = False))
```

![[Pasted image 20250523082242.png]]

ÄŒe pa nastavimo verbose na True, se bo izpisala tabela in pa show_counters damo na False se ne bo izpisalo Å¡tevilo vrstic, ki imajo nonull vrednosti. 

```
print(result_of_csv_read.info(verbose=True, show_counts=False))
```


![[Pasted image 20250523082415.png]]


- describe() - Metoda describe() vrne opis podatkov v podatkovnem okviru (DataFrame).

  ÄŒe podatkovni okvir vsebuje numeriÄne podatke, opis vsebuje te podatke za vsak stolpec:

  count - Å tevilo nepraznih vrednosti.
  mean - PovpreÄna (aritmetiÄna) vrednost.
  std - Standardni odklon.
  min - NajmanjÅ¡a vrednost.
  25 % - 25 % percentil*.
  50 % - 50 % percentil*.
  75 % - 75 % percentil*.
  max - NajviÅ¡ja vrednost.

![[Pasted image 20250523084329.png]]

*********************************************************

**PRIPRAVA PODATKOV**
"""""""""""""""""""""""""

Cilje je da oÄistimo in popravimo podatke za model. 

Potrebno je: 

- Ugotovi manjkajoÄe vrednosti in jih odpravi (`df.isnull().sum()`)

- Razdeli podatke na **X (vhodni podatki)** in **y (izhod â€“ cena)**

- Standardiziraj vrednosti (npr. `StandardScaler()` iz `sklearn.preprocessing`)

- Razdeli na **trening in testni set** (`train_test_split`)


1. Odprava manjkajoÄih vrednosti - df.isnull().sum()
	- Ta funkcija nam omogoÄa preÅ¡teti, koliko podatkov ima NULL vrednost

```
import pandas as pd 

result_of_csv_read = pd.read_csv('HousingData.csv')

print(result_of_csv_read.isnull().sum())

```

![[Pasted image 20250523085629.png]]

2. Razdelimo podatke na **X (vhodni podatki)** in **y (izhod â€“ cena)**
## Razlaga stolpcev (podatki iz Bostonskega stanovanjskega sklopa):

|Stolpec|Pomen|
|---|---|
|**CRIM**|Kriminalna stopnja po naselju|
|**ZN**|Procent stanovanjskih con za stanovanja > 25.000 ftÂ²|
|**INDUS**|Procent poslovnih obmoÄij (nekmetijska raba)|
|**CHAS**|Meja s Charles River (1 = da, 0 = ne)|
|**NOX**|OnesnaÅ¾enost zraka (duÅ¡ikovi oksidi)|
|**RM**|PovpreÄno Å¡tevilo sob na stanovanjsko enoto|
|**AGE**|Procent stanovanj, zgrajenih pred 1940|
|**DIS**|Razdalja do petih pomembnih delovnih srediÅ¡Ä v Bostonu|
|**RAD**|Indeks dostopa do avtocest|
|**TAX**|DavÄna stopnja na nepremiÄnine|
|**PTRATIO**|Razmerje uÄencev na uÄitelja po obÄini|
|**B**|1000(Bk - 0.63)^2, kjer je Bk deleÅ¾ temnopoltih prebivalcev|
|**LSTAT**|Procent niÅ¾jega socialno-ekonomskega sloja|
|**MEDV**|ğŸ”¥ Mediana vrednosti hiÅ¡ v tisoÄih dolarjev (to je cilj â€“ `y`)|
Ker Å¾elimo poizvedeti kako se spreminjajo cene hiÅ¡, bomo vzeli podatek MEDV. 

ÄŒe Å¾elimo poizvedeti kateri podatki najbolje korelirajo med sabo moramo narediti korelacijsko matriko (heatmap): 

````
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

result_of_csv_read = pd.read_csv('HousingData.csv')

corr_matrix = result_of_csv_read.corr()

plt.figure(figsize=(10, 8))

sns.heatmap(corr_matrix, annot=True, cmap="coolwarm")

plt.show()

````

Tole je pa rezultat kode:
![[Pasted image 20250523094630.png]]

### Najbolj pomembne povezave s `MEDV`:

|Spremenljivka|Korelacija z `MEDV`|Pomen|
|---|---|---|
|**RM**|**+0.70**|VeÄ sob â†’ viÅ¡ja cena|
|**LSTAT**|**-0.72**|VeÄ revnih â†’ niÅ¾ja cena|
|**PTRATIO**|-0.51|VeÄ uÄencev na uÄitelja â†’ niÅ¾ja cena|
|**INDUS**|-0.48|VeÄ industrije â†’ niÅ¾ja cena|
|**TAX**|-0.47|ViÅ¡ji davek â†’ niÅ¾ja cena|
|**NOX**|-0.43|OnesnaÅ¾enje â†’ niÅ¾ja cena|
|**CRIM**|-0.38|Kriminal â†’ niÅ¾ja cena|
|**AGE**|-0.38|StarejÅ¡e soseske â†’ niÅ¾ja cena|
|**B**|+0.33|(kompleksna etniÄna formula â€“ pogosto manj pomembna)|

Mi bomo uporabili kar vse podatke in dali MDEV na Y os. 

Podatke smo tudi razdelili na uÄno in testno mnoÅ¾ico s pomoÄjo train_test_split funkcije. 

Naredili smo tudi STANDARDIZACIJO, ker nekateri podatki delujejo bolje, Äe so v isti skali. To smo naredili s pomoÄjo knjiÅ¾nice StandardScaler(). 

Tukaj je celotna koda:
```
import pandas as pd 

import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split

from sklearn.preprocessing import StandardScaler

#Preberemo csv file
result_of_csv_read = pd.read_csv('HousingData.csv')


result_of_csv_read = result_of_csv_read.fillna(result_of_csv_read.mean(numeric_only=True))

#print(result_of_csv_read.isnull().sum()) # zdej mamo prazne podatke zafilane s povprecno vrednostjo stolpca

#Razdelimo podatke na X in pa Y os

X = result_of_csv_read.drop("MEDV", axis = 1)
Y = result_of_csv_read["MEDV"]

#Razdelimo podatke na uÄno enoto in testno mnoÅ¾ico

X_train, X_test, Y_train, Y_test = train_test_split (
    X, Y, test_size=0.2, random_state=42

)

#Standardizacija

scaler = StandardScaler()

X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

"Pomembno: Vedno uporabi fit_transform() samo na uÄni mnoÅ¾ici â€“ testno le transform()!"


```

*****************************************
**GRAJENJE IN TRENIRANJE MODELOV**

Uporabili bomo linearno regresijo. 

```
from sklearn.linear_model import LinearRegression
model = LinearRegression()
model.fit(X_train, Y_train)
```

*******************************
EVALVACIJA MODELA

Tukaj bomo izmerili natanÄnost modela.

```
from sklearn.metrics import mean_squared_error, r2_score
predictions = model.predict(X_test)

mse = mean_squared_error(y_test, predictions)
r2 = r2_score(y_test, predictions)

```

*****************
SHRANIMO MODEL


```
import joblib
joblib.dump(model, "house_price_model.pkl")

```

Celotna koda se nahaja v mapi Napoved cene hiÅ¡e. 

 DODATEK: 

Dodal sem se Vizualizacijo, kjer primerjaÅ¡ dejanske in napovedane cene, kako shranimo modele, analiza - kaj vpliva na ceno ter napredno matriko (RMSE ali MAE).

![[Pasted image 20250523101717.png]]

![[Pasted image 20250523101733.png]]

